{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Language Model using Financial Reporting Standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a modified notebook taken from the FastAI Deep Learning course [Lesson 4](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson4-imdb.ipynb) and [Lesson 6](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-rnn.ipynb). This was an experiment to see whether a model from the FastAI library trained using Financial Reporting Standards (FRS) data can give coherent answers when prompted with accounting queries. The data used are the [Financial Reporting Standards (2018)](https://www.asc.gov.sg/frs2018volume). We will be trying out a word level and character level language model separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyk/anaconda3/envs/fastai/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "import html\n",
    "\n",
    "import dill as dill\n",
    "import spacy\n",
    "import textract\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "path=Path('/home/lyk/Documents/FRS2018')\n",
    "spacy_tok = spacy.load('en')\n",
    "TEXT = data.Field(lower=True, tokenize=\"spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion of FRS PDFs to text format using [Textract](https://github.com/deanmalmgren/textract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convert pdf to text\n",
    "# for fname in path.glob('*.pdf'):\n",
    "#     new_fname = re.search('.{28}(.+).pdf',str(fname)).group(1)\n",
    "#     with open(path/f'txt/{new_fname}.txt', 'w') as f:\n",
    "#         f.write(re.sub('\\n+',' ',textract.process(fname).decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRS Word Level Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 2782, 1, 603442)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT=data.Field(lower=True,tokenize='spacy')\n",
    "\n",
    "bs=32 #batch-size\n",
    "bptt=70 #bptt backprop-through-time: how many tokens to put in at once (i.e. 70)\n",
    "\n",
    "FILES = dict(train=path/'txt/train', validation=path/'txt/val', test=path/'txt/val')\n",
    "md = LanguageModelData.from_text_files(path, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "\n",
    "#dill.dump(TEXT, open(path/'TEXT.pkl','wb'))\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', 'of', ',', '.', 'in', 'a', 'to', ')', 'and', '(']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200  # size of each embedding vector (50-600 is a good number)\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1) # to reduce overfitting\n",
    "learner.clip=0.3 #don't let gradient(?) be more than 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `lr_find()` is an implementaion by FastAI of the 2015 paper [Cyclical Learning Rates for Training Neural Networks](http://arxiv.org/abs/1506.01186) to find a good value to set the learning rate. Choosing a high enough learning rate where the validation loss is still improving will speed up training while maintaining model performance. From the chart, a learning rate of 1e-2 seems to be the most appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5cdb18eb934db7a0541817b55e0126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 254/268 [00:12<00:00, 19.97it/s, loss=19.7]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wds refers to weight decay (L2 Regularization)\n",
    "- cycle_len refers to how long to gradually decrease the learning rate in one epoch (The FastAI Library uses cosine annealing)\n",
    "- cycle_mult is how much to multiply the length of one epoch after the previous epoch finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4d29b34c6f4775b453d1624dd377b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.851322   5.759224  \n",
      "    1      5.859929   5.874969                              \n",
      "    2      5.788686   5.720853                              \n",
      "    3      4.803605   4.667127                              \n",
      "    4      4.030635   4.132255                              \n",
      "    5      3.749445   3.933609                              \n",
      "    6      3.647808   3.871671                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.87167])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(1e-2, 3, wds=1e-5, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model starts to overfit slightly after 3 epochs as the validation loss starts becoming greater than the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam3_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=learner.model\n",
    "sentence='a liability is'\n",
    "s_tok = [spacy_tok(sentence)]\n",
    "t=TEXT.numericalize(s_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a liability is \n",
      "\n",
      "( a ) the amount of the consideration received ( or receivable ) in the period in which the entity has a right to receive cash or another financial asset to the entity . ( b ) the entity has a right to receive cash or another financial asset to another entity . the entity ’s own equity instruments are not recognised in the entity ’s statement of financial position . the entity ’s share of the net assets of the entity ’s net assets of the entity and the entity ’s own equity instruments are not recognised in profit ...\n"
     ]
    }
   ],
   "source": [
    "print(sentence,\"\\n\")\n",
    "for i in range(100):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the query actually came out decently even though it is not entirely correct. When given more complex queries, the model does not perform as well and will tend to give less coherent answers as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=learner.model\n",
    "sentence='an intangible asset is measured at'\n",
    "s_tok = [spacy_tok(sentence)]\n",
    "t=TEXT.numericalize(s_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an intangible asset is measured at \n",
      "\n",
      ", the entity ’s own equity instruments , the entity shall disclose the following : ( a ) the entity ’s financial statements ( see paragraph 10 ) . ( b ) the entity ’s financial statements ( see paragraph 10 ) . ( b ) the entity ’s financial statements ( see paragraph 10 ) . ( b ) the entity ’s financial statements ( see paragraph 10 ) . ( b ) the entity ’s financial statements in accordance with frs 109 . the entity shall recognise the following : ( a ) the entity ’s financial statements ...\n"
     ]
    }
   ],
   "source": [
    "print(sentence,\"\\n\")\n",
    "for i in range(100):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRS Character level Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 4475064\n"
     ]
    }
   ],
   "source": [
    "text_list=[]\n",
    "for fname in (path/'txt').glob('*.txt'):\n",
    "    text_list.append(open(fname).read())\n",
    "\n",
    "text = [i for o in text_list for i in o]\n",
    "\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 110\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total unique characters:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\x0c $%&'()*+,-./0123456789:;=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^abcdefghijklmnopqrstuvwxyz{}\\x80\\x93\\x99£¥±×â÷‒–—‘’“”\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}\n",
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTERPRETATION OF FINANCIAL REPORTING STANDARD INT FRS 114 FRS 19—The '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import sgdr\n",
    "\n",
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from the FastAI Deep Learning course Lesson 6 notebook\n",
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): #for LSTM, need to return a tuple\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{path}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2133d0c6ff374e17a35db969a5049b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      1.065968   1.130509  \n",
      "    1      0.984975   1.082506                                 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.08251])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffc09d568e247d6b0ef419d36996dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.835457   0.891636  \n",
      "    1      0.83892    0.891646                                 \n",
      "    2      0.84007    0.891638                                 \n",
      "    3      0.838736   0.891641                                 \n",
      "    4      0.839379   0.891636                                 \n",
      "    5      0.84146    0.89164                                  \n",
      "    6      0.846703   0.891636                                 \n",
      "    7      0.840565   0.891643                                 \n",
      "    8      0.837558   0.891634                                 \n",
      "    9      0.836777   0.891635                                 \n",
      "    10     0.840028   0.891632                                 \n",
      "    11     0.835383   0.891631                                 \n",
      "    12     0.840804   0.891637                                 \n",
      "    13     0.840058   0.891636                                 \n",
      "    14     0.839098   0.891629                                 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.89163])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{path}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)] #learning rate with Cosine Annealing \n",
    "fit(m, md, 15, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 15 epochs, the training and validation loss did not improve and the model remained similarly overfitted throughout. The relatively poorer result can be seen below when given the same query as when testing the word level language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]\n",
    "\n",
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a liability is an investment in accordance with frs 3 example 104, the entity two identifies estimating the taxble integration when the maintenance of its profit or loss or a first-time adopted differ securities in owner-quved is not part in accursantly; (b) costs increase the deferral accounting policies. however, priacipally may significant amounts require entity d  ie281 (b) individual ? financial liabilitie\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('a liability is', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the FRS corpus alone is not enough to get a generalizable language model for accounting queries. Possible ways to improve this model would be to gather more documents related to financial reporting standards, do data augmentation to existing text data or combining both the word level and character level language models. <br> \n",
    "Another way would be to do transfer learning by using a pre-trained language model and fine-tuning the last few layers with the FRS corpus, as demonstrated with the IMDB data set in [Lesson 10](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb) of the FastAI Deep Learning course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
